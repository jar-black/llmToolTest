# Models currently in config (original 3)
qwen2.5:7b
llama3.1:8b
mistral-nemo:12b

# Additional tool-calling models (10 new models, all under 14GB)

# Qwen 2.5 Coder - Excellent at structured outputs and tool calling
qwen2.5-coder:7b

# Hermes 3 - Specifically trained for function calling and tool use
hermes3:8b

# Command-R - Cohere's model optimized for RAG and tool use
command-r:7b

# Granite 3 Dense - IBM's model with strong tool calling capabilities
granite3-dense:8b

# Llama 3.2 3B - Smaller but capable Meta model
llama3.2:3b

# Phi 3.5 - Microsoft's efficient model with good reasoning
phi3.5:3.8b

# Qwen 2.5 3B - Smaller Qwen variant, still good at tools
qwen2.5:3b

# Mistral 7B v0.3 - Classic Mistral with tool calling support
mistral:7b-instruct-v0.3

# Gemma 2 9B - Google's model with strong instruction following
gemma2:9b

# Aya 8B - Cohere's multilingual model with tool support
aya:8b

# ============================================================================
# Additional high-performing tool calling models (Research from 2025)
# ============================================================================

# xLAM Models - Salesforce's Large Action Models, top performers on Berkeley Function Calling Leaderboard
# xLAM-7b-fc-r ranked #1 and xLAM-1b-fc-r ranked #6 on BFCL
allenporter/xlam:1b
allenporter/xlam:7b

# DeepSeek R1 Distilled Models - Excellent reasoning and tool calling from DeepSeek
# Distilled versions based on Qwen/Llama with strong tool calling support
deepseek-r1:1.5b
deepseek-r1:7b
deepseek-r1:8b

# Granite 3.1 Models - IBM's models optimized for enterprise tool use and RAG
# Both Dense and MoE (Mixture of Experts) variants
granite3.1-moe:1b
granite3.1-moe:3b
granite3.1-dense:2b

# Nemotron Mini - NVIDIA's small model optimized for function calling and RAG
nemotron-mini:4b

# Hermes 3 Smaller Variant - NousResearch model with strong function calling
# Built on Llama 3.2, uses ChatML format with structured tool calling
hermes3:3b

# Llama 3.2 1B - Meta's smallest Llama 3.2 with tool calling support
llama3.2:1b

# Phi-4 - Microsoft's latest model with function calling capabilities
# 14B parameters, around 8-9GB quantized
phi4:14b

# Mistral 7B Base - Mistral AI's base 7B model with tool support
mistral:7b

# Llama 3.3 8B - Latest Llama version with improved tool calling
llama3.3:8b
